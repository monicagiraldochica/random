<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>How to install Open Composer</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
  <link href="style.css" rel="stylesheet">
</head>
<body>

  <div class="container-fluid">
    <nav class="sidebar bg-body-secondary">
      <h5 class="ps-3 pe-1 d-inline">Contents</h5>
      <ul class="nav flex-column px-3 py-2">
        <li class="nav-item"><a href="#install" class="nav-link">1. Installation</a></li>
        <li class="nav-item"><a href="#setting" class="nav-link">2. Setting</a></li>
	<li class="nav-item ms-3"><a href="#clusters" class="nav-link">2.1. clusters</a></li>
	<li class="nav-item ms-3"><a href="#bin_overrides" class="nav-link">2.2. bin_overrides</a></li>
	<li class="nav-item ms-3"><a href="#history" class="nav-link">2.3. history</a></li>
	<li class="nav-item"><a href="#registor" class="nav-link">3. Registration for Open OnDemand</a></li>
	<li class="nav-item ms-3"><a href="#admin" class="nav-link">3.1. By administrator</a></li>
        <li class="nav-item ms-3"><a href="#general" class="nav-link">3.2. By general user</a></li>
	<li class="nav-item"><a href="#jobscheduler" class="nav-link">4. Adding job scheduler</a></li>
      </ul>
    </nav>

    <main class="main-content">
      <h1>How to install Open Composer</h1>
      <h2 id="install">1. Installation</h2>
      <p>
	Open Composer runs on <a target="_blank" href="https://openondemand.org/">Open OnDemand</a>. Save Open Composer in your Open OnDemand application directory: <code>/var/www/ood/apps/sys/</code>.
      </p>
      <pre>
# cd /var/www/ood/apps/sys/
# git clone https://github.com/RIKEN-RCCS/OpenComposer.git
</pre>

      <h2 id="setting">2. Setting</h2>
      <p>
	Create <code>./conf.yml.erb</code> with reference to <code>./conf.yml.erb.sample</code>.
      </p>
      <pre># cd OpenComposer
# cp conf.yml.erb.sample conf.yml.erb
</pre>
      <table class="table">
	<tr><th>Item name</th><th>Setting</th></tr>
	<tr><td>apps_dir</td><td>Application directory</td></tr>
	<tr><td>scheduler</td><td>Job scheduler (<code>slurm</code>, <code>pbspro</code>, <code>sge</code>, <code>fujitsu_tcs</code>)</td></tr>
	<tr><td>clusters</td><td>Cluster properties</td></tr>
	<tr><td>data_dir</td><td>Directory where submitted job information is stored (Default is <code>${HOME}/composer</code>)</td></tr>
	<tr><td>login_node</td><td>Login node when you launch the Open OnDemand web terminal</td></tr>
	<tr><td>ssh_wrapper</td><td>Command for using the job scheduler of another node using SSH</td></tr>
	<tr><td>bin</td><td>PATH of commands of job scheduler</td></tr>
	<tr><td>bin_overrides</td><td>PATH of each command of job scheduler</td></tr>
	<tr><td>sge_root</td><td>Directory for the Grid Engine root (<code>SGE_ROOT</code>)</td></tr>
	<tr><td>history</td><td>Additional display fields on the history page</td></tr>
	<tr><td>footer</td><td>Text in the footer</td></tr>
	<tr><td>thumbnail_width</td><td>Width of thumbnails for each application on the home page</td></tr>
	<tr><td>navbar_color</td><td>Color of navigation bar</td></tr>
	<tr><td>dropdown_color</td><td>Color of dropdown menu</td></tr>
	<tr><td>footer_color</td><td>Color of footer</td></tr>
	<tr><td>category_color</td><td>Background color of the home page category</td></tr>
	<tr><td>description_color</td><td>Background color of the application description in the application page</td></tr>
	<tr><td>form_color</td><td>Background color of the text area in the application page</td></tr>
      </table>
      <p>
	The <code>apps_dir</code> and <code>scheduler</code> are required. However, the <code>scheduler</code> may be defined inside <code>clusters</code>.
      </p>
      
      <h3 id="clusters">2.1. clusters</h3>
      <p>
	Set this when using multiple clusters.
	You can set <code>scheduler</code>, <code>login_node</code>, <code>ssh_wrapper</code>, <code>bin</code>, <code>bin_overrides</code>, and <code>sge_root</code> for each cluster.
	This setting is optional if you use only a single cluster.
      </p>
      <p>
	The following defines the use of the <code>fujitsu_tcs</code> and <code>slurm</code> job schedulers on the <code>fugaku</code> and <code>prepost</code> clusters, respectively.
      </p>
      <pre>clusters:
  fugaku:
    scheduler: "fujitsu_tcs"
  prepost:
    scheduler: "slurm"
    bin_overrides:
      sbatch: "/usr/local/bin/sbatch"</pre>

      <p>
	In the following, both the <code>fugaku</code> and <code>prepost</code> clusters use the <code>slurm</code> job scheduler, but it defines that <code>slurm</code> is executed from different machines.
      </p>
      <pre>scheduler: "slurm"
clusters:
  fugaku:
    ssh_wrapper "ssh fugaku.example.net"
  prepost:
    ssh_wrapper "ssh prepost.example.net"</pre>
    
      <h3 id="bin_overrides">2.2. bin_overrides</h3>
      <p>
	Set the path for each command. This setting is optional.
      </p>
      <p>
	If the job scheduler is <code>slurm</code>, set <code>sbatch</code>, <code>scontrol</code>, <code>scancel</code>, and <code>sacct</code> as follows.
      </p>
      <pre>bin_overrides:
  sbatch:   "/usr/local/bin/sbatch"
  scontrol: "/usr/local/bin/scontrol"
  scancel:  "/usr/local/bin/scancel"
  sacct:    "/usr/local/bin/sacct"</pre>

      <p>
	If the job scheduler is <code>pbspro</code>, set <code>qsub</code>, <code>qstat</code>, and <code>qdel</code> as follows.
      </p>
      <pre>bin_overrides:
  qsub:   "/usr/local/bin/qsub"
  qstat: "/usr/local/bin/qstat"
  qdel:  "/usr/local/bin/qdel"</pre>

      <p>
	If the job scheduler is <code>sge</code>, set <code>qsub</code>, <code>qstat</code>, <code>qdel</code>, and <code>qacct</code> as follows.
      </p>
      <pre>bin_overrides:
  qsub:   "/usr/local/bin/qsub"
  qstat: "/usr/local/bin/qstat"
  qdel:  "/usr/local/bin/qdel"
  qacct: "/usr/local/bin/qacct"</pre>

      <p>
	If the job scheduler is <code>fujitsu_tcs</code>, set <code>pjsub</code>, <code>pjstat</code>, and <code>pjdel</code> as follows.
      </p>
      <pre>bin_overrides:
  pjsub:  "/usr/local/bin/pjsub"
  pjstat: "/usr/local/bin/pjstat"
  pjdel:  "/usr/local/bin/pjdel"</pre>

      <h3 id="history">2.3. history</h3>
      <p>
	The mandatory fields to be displayed on the history page are "Job ID", "Application", "Script Name", and "Status".
	In addition to these, optional display fields can be configured.
	This configuration is optional.
      </p>
      <p>
	If nothing is specified in <code>history</code>, "Job Name", "Partition", and "Submission Time" are automatically set. 
	This is equivalent to the code shown below. 
	<code>OC_HISTORY_JOB_NAME</code>, <code>OC_HISTORY_PARTITION</code>, and <code>OC_HISTORY_SUBMISSION_TIME</code> are special variables that correspond to "Job Name", "Partition", and "Submission Time", respectively.
      </p>
      <pre>history:
  OC_HISTORY_JOB_NAME:
  OC_HISTORY_PARTITION:
  OC_HISTORY_SUBMISSION_TIME:</pre>
      <img width="800" src="./img/history_table1.png">
      <p>
	If you want to disable additional display fields, define an empty array.
      </p>
      <pre>history: []</pre>
      <img width="800" src="./img/history_table2.png">
      <p>
	You can set profile values obtained from the job scheduler as display fields.
	Specify in <code>history</code> the value shown in the left column of the table that appears when you click "Job ID".
	By using <code>label</code>, you can define a display label.
	If <code>label</code> is not specified, the profile value is used as is.
      </p>
      <img width="400" src="./img/history_table3.png">
      <pre>history:
  OC_HISTORY_JOB_NAME:
  Account:
  AllocCPUS:
    label: Allocated CPUs</pre>
      <img width="800" src="./img/history_table4.png">
      
      <h2 id="registor">3. Registration for Open OnDemand</h2>
      <h3 id="admin">3.1. By administrator</h3>
      <p>
	When you save Open Composer to <code>/var/www/ood/apps/sys/</code>, the Open Composer icon will be displayed on the Open OnDemand home page.
If it is not displayed, check <code>/var/www/ood/apps/sys/OpenComposer/manifest.yml</code>.
      </p>
      <p>
	You can also display Open Composer applications on the Open OnDemand home page.
	For example, if you want to display an application <code>/var/www/ood/apps/sys/OpenComposer/sample_apps/Slurm</code>,
	create a directory with the same name in the Open OnDemand application directory (<code># mkdir /var/www/ood/apps/sys/Slurm</code>).
	Then, create the following Open OnDemand configuration file <code>manifest.yml</code> in that directory.
      </p>

      <pre># /var/www/ood/apps/sys/Slurm/manifest.yml
---
name: Slurm
url: https://&lt;your Open OnDemand URL&gt;/pun/sys/OpenComposer/Slurm</pre>

      <h3 id="general">3.2. By general user</h3>
      <p>
	You can also install Open Composer with general user privileges.
	However, the <a target="_blank" href="https://osc.github.io/ood-documentation/latest/how-tos/app-development/enabling-development-mode.html">App Development</a> feature in Open OnDemand needs to be enabled in advance by an administrator.
      </p>
      <p>
	Select "My Sandbox Apps (Development)" under "&lt;/&gt; Develop" in the navigation bar (If your web browser window size is small, it will display "&lt;/&gt;" instead of "&lt;/&gt; Develop").
      </p>
      <img src="img/navbar.png" width="250" alt="Navbar">
      <p>
	Click "New App".
      </p>
      <img src="img/newapp.png" width="250" alt="New App">
      <p>
	Click "Clone Existing App".
      </p>
      <img src="img/clone.png" width="400" alt="Clone an existing app">
      <p>
	Enter any name in "Directory name" (here we enter OpenComposer), enter "<a target="_blank" href="https://github.com/RIKEN-RCCS/OpenComposer.git">https://github.com/RIKEN-RCCS/OpenComposer.git</a>" in "Git remote", and click "Submit".
      </p>
      <img src="img/new_repo.png" width="800" alt="New repository">
      <p>
	Click "Launch Open Composer".
      </p>
      <img src="img/bundle.png" width="800" alt="Bundle Install">

      <h2 id="jobscheduler">4. Adding a Job Scheduler</h2>
      <p>
	If you want to add a job scheduler, create a Ruby script for the job scheduler under <code>lib/schedulers/</code> using the superclass Scheduler defined in <code>lib/scheduler.rb</code> as a reference. Inherit the Scheduler class as shown in the PBS Pro example below (<code>lib/schedulers/pbspro.rb</code>).
	You must define the <code>submit()</code> method for submitting a job, the <code>cancel()</code> method for canceling a job, and the <code>query()</code> method for querying job information.
      </p>
      <pre>class Pbspro &lt; Scheduler</pre>
      <p>
	Also, in some clusters, job scheduler commands (e.g., <code>qstat</code>) are wrapper scripts, making it impossible for users to execute the original commands. In such cases, you may be able to address this issue by making minor changes to the existing scheduler script. For example, in <code>lib/schedulers/miyabi.rb</code>, a new class, Miyabi, is defined by inheriting the PBS Pro scheduler, as shown below. The Miyabi class defines only the <code>query()</code> method, while the other methods use those defined in <code>lib/schedulers/pbspro.rb</code>.
      </p>
      <pre>class Miyabi &lt; Pbspro</pre>
      <p>
	After creating the job scheduler script, specify the scheduler in <code>./conf.yml.erb</code> as shown below.
      </p> 
      <pre>scheduler: miyabi</pre>
      
    </main>
  </div>
  
  <footer class="d-flex justify-content-center">
    <p class="mb-0 text-white">&copy; RIKEN Center for Computational Science</p>
  </footer>
</body>
</html>
